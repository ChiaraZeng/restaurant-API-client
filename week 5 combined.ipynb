{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76acafd0-3214-4488-9108-20c3b047d6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           name  \\\n",
      "0           La Grande Boucherie   \n",
      "1                    The Modern   \n",
      "2                STK Steakhouse   \n",
      "3              Tony's Di Napoli   \n",
      "4  La Pecora Bianca Bryant Park   \n",
      "\n",
      "                                            address  rating  price_level  \\\n",
      "0  145 W 53rd St, New York, NY 10019, United States     4.6          2.0   \n",
      "1    9 W 53rd St, New York, NY 10019, United States     4.6          4.0   \n",
      "2   1114 6th Ave, New York, NY 10036, United States     4.8          3.0   \n",
      "3  147 W 43rd St, New York, NY 10036, United States     4.6          2.0   \n",
      "4   20 W 40th St, New York, NY 10018, United States     4.7          3.0   \n",
      "\n",
      "    latitude  longitude  source  \n",
      "0  40.762634 -73.980836  google  \n",
      "1  40.761081 -73.976753  google  \n",
      "2  40.754721 -73.982759  google  \n",
      "3  40.756462 -73.985397  google  \n",
      "4  40.752518 -73.983153  google  \n",
      "✅ Saved cleaned Google dataset to google_restaurants_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load combined Google data from Week 4\n",
    "df_google = pd.read_csv(\"google_all_restaurants_combined.csv\")\n",
    "\n",
    "# Normalize nested fields using dot notation for access\n",
    "# (Assumes this step was already done in Week 4 using json_normalize with sep='.')\n",
    "# But in case you're redoing from raw JSON:\n",
    "# df_google = pd.json_normalize(google_data, sep='.')\n",
    "\n",
    "# Add a source column\n",
    "df_google['source'] = 'google'\n",
    "\n",
    "# Rename fields for consistency\n",
    "df_google.rename(columns={\n",
    "    'formatted_address': 'address',\n",
    "    'rating': 'rating',\n",
    "    'price': 'price_level',\n",
    "    'geometry.location.lat': 'latitude',\n",
    "    'geometry.location.lng': 'longitude'\n",
    "}, inplace=True)\n",
    "\n",
    "# Some fields may not exist in all rows — ensure they exist to avoid KeyError\n",
    "for col in ['address', 'rating', 'price_level', 'latitude', 'longitude']:\n",
    "    if col not in df_google.columns:\n",
    "        df_google[col] = None\n",
    "\n",
    "# Keep only required columns\n",
    "columns_needed = ['name', 'address', 'rating', 'price_level', 'latitude', 'longitude', 'source']\n",
    "df_google_clean = df_google[columns_needed]\n",
    "\n",
    "# Preview\n",
    "print(df_google_clean.head())\n",
    "\n",
    "# Optional: Save cleaned Google data\n",
    "df_google_clean.to_csv(\"google_restaurants_cleaned.csv\", index=False)\n",
    "print(\"✅ Saved cleaned Google dataset to google_restaurants_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f41d15f3-1c17-491c-8fcf-86e1b36a83d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             name  \\\n",
      "0                 Los Tacos No. 1   \n",
      "1                Black Fox Coffee   \n",
      "2                       The Odeon   \n",
      "3       Laughing Man Coffee & Tea   \n",
      "4  The Dead Rabbit Grocery & Grog   \n",
      "\n",
      "                                             address rating  price_level  \\\n",
      "0  136 Church St (btw Murray & Warren), New York,...   None          NaN   \n",
      "1                     70 Pine St, New York, NY 10005   None          NaN   \n",
      "2  145 W Broadway (at Thomas St), New York, NY 10013   None          NaN   \n",
      "3  184 Duane St (btwn Greenwich & Hudson St.), Ne...   None          NaN   \n",
      "4  30 Water St (btwn Broad St & Coenties Slip), N...   None          NaN   \n",
      "\n",
      "    latitude  longitude      source  \n",
      "0  40.714290 -74.008730  foursquare  \n",
      "1  40.706441 -74.007808  foursquare  \n",
      "2  40.716902 -74.007873  foursquare  \n",
      "3  40.717216 -74.010199  foursquare  \n",
      "4  40.703164 -74.010953  foursquare  \n",
      "✅ Saved cleaned Foursquare dataset to foursquare_restaurants_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Foursquare data from Week 4\n",
    "df_fsq = pd.read_csv(\"foursquare_all_restaurants_combined.csv\")\n",
    "\n",
    "# Add source column\n",
    "df_fsq['source'] = 'foursquare'\n",
    "\n",
    "# Rename fields for consistency\n",
    "df_fsq.rename(columns={\n",
    "    'location.formatted_address': 'address',\n",
    "    'rating': 'rating',\n",
    "    'price': 'price_level',\n",
    "    'geocodes.main.latitude': 'latitude',\n",
    "    'geocodes.main.longitude': 'longitude'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ensure all necessary columns exist\n",
    "for col in ['address', 'rating', 'price_level', 'latitude', 'longitude']:\n",
    "    if col not in df_fsq.columns:\n",
    "        df_fsq[col] = None\n",
    "\n",
    "# Select only required columns\n",
    "columns_needed = ['name', 'address', 'rating', 'price_level', 'latitude', 'longitude', 'source']\n",
    "df_fsq_clean = df_fsq[columns_needed]\n",
    "\n",
    "# Preview\n",
    "print(df_fsq_clean.head())\n",
    "\n",
    "# Optional: save cleaned data\n",
    "df_fsq_clean.to_csv(\"foursquare_restaurants_cleaned.csv\", index=False)\n",
    "print(\"✅ Saved cleaned Foursquare dataset to foursquare_restaurants_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "782718bd-f27b-4527-a4bd-df025e06905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined dataset saved to combined_restaurants_cleaned.csv and combined_restaurants.db\n"
     ]
    }
   ],
   "source": [
    "# Load both cleaned datasets\n",
    "df_google_clean = pd.read_csv(\"google_restaurants_cleaned.csv\")\n",
    "df_fsq_clean = pd.read_csv(\"foursquare_restaurants_cleaned.csv\")\n",
    "\n",
    "# Combine\n",
    "df_combined = pd.concat([df_google_clean, df_fsq_clean], ignore_index=True)\n",
    "\n",
    "# Save combined data\n",
    "df_combined.to_csv(\"combined_restaurants_cleaned.csv\", index=False)\n",
    "\n",
    "# Optional: Save to SQLite\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"combined_restaurants.db\")\n",
    "df_combined.to_sql(name='restaurants', con=conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ Combined dataset saved to combined_restaurants_cleaned.csv and combined_restaurants.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf76d66-113c-4434-ba5f-3e8feb688793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           name  \\\n",
      "0           La Grande Boucherie   \n",
      "1                    The Modern   \n",
      "2                STK Steakhouse   \n",
      "3              Tony's Di Napoli   \n",
      "4  La Pecora Bianca Bryant Park   \n",
      "5                            53   \n",
      "6       Carmine's - Time Square   \n",
      "7               Osteria La Baia   \n",
      "8                     The Smith   \n",
      "9                  Le Bernardin   \n",
      "\n",
      "                                            address  rating  price_level  \\\n",
      "0  145 W 53rd St, New York, NY 10019, United States     4.6          2.0   \n",
      "1    9 W 53rd St, New York, NY 10019, United States     4.6          4.0   \n",
      "2   1114 6th Ave, New York, NY 10036, United States     4.8          3.0   \n",
      "3  147 W 43rd St, New York, NY 10036, United States     4.6          2.0   \n",
      "4   20 W 40th St, New York, NY 10018, United States     4.7          3.0   \n",
      "5   53 W 53rd St, New York, NY 10019, United States     4.3          3.0   \n",
      "6  200 W 44th St, New York, NY 10036, United States     4.5          2.0   \n",
      "7  129 W 52nd St, New York, NY 10019, United States     4.8          4.0   \n",
      "8    956 2nd Ave, New York, NY 10022, United States     4.4          2.0   \n",
      "9  155 W 51st St, New York, NY 10019, United States     4.6          4.0   \n",
      "\n",
      "    latitude  longitude  source  \n",
      "0  40.762634 -73.980836  google  \n",
      "1  40.761081 -73.976753  google  \n",
      "2  40.754721 -73.982759  google  \n",
      "3  40.756462 -73.985397  google  \n",
      "4  40.752518 -73.983153  google  \n",
      "5  40.761769 -73.978086  google  \n",
      "6  40.757498 -73.986654  google  \n",
      "7  40.761813 -73.980849  google  \n",
      "8  40.755229 -73.968056  google  \n",
      "9  40.761422 -73.981756  google  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"combined_restaurants.db\")\n",
    "\n",
    "# Preview first 10 rows from the 'restaurants' table\n",
    "query = \"SELECT * FROM restaurants LIMIT 10\"\n",
    "df_preview = pd.read_sql(query, conn)\n",
    "\n",
    "# Display the result\n",
    "print(df_preview)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d0f08-5627-4bf2-893c-7aa45fca4f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
